version: '3.8'  # Specify the version of Docker Compose

services:
  # PostgreSQL service
  postgres:
    image: postgres:13  # Use the official PostgreSQL image version 13
    environment:
      POSTGRES_USER: airflow  # Set the PostgreSQL user to 'airflow'
      POSTGRES_PASSWORD: airflow  # Set the PostgreSQL password to 'airflow'
      POSTGRES_DB: airflow  # Set the PostgreSQL database name to 'airflow'
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data  # Persist PostgreSQL data

  # Airflow webserver service
  webserver:
    image: apache/airflow:2.4.3  # Use the official Apache Airflow image version 2.4.3
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor  # Use LocalExecutor for Airflow
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow  # Database connection string
      #AIRFLOW__CORE__FERNET_KEY: 'OExH4KfzQbFU9f2DltIorH3jDP6bHCjSIOXcjssHImM='  # Optional: Fernet key for encryption
      AIRFLOW__CORE__LOAD_EXAMPLES: 'true'  # Load example DAGs
      AIRFLOW__WEBSERVER__RBAC: 'true'  # Enable Role-Based Access Control (RBAC)
    volumes:
      - ./dags:/opt/airflow/dags  # Mount local 'dags' directory to Airflow 'dags' directory
      - ./logs:/opt/airflow/logs  # Mount local 'logs' directory to Airflow 'logs' directory
      - ./plugins:/opt/airflow/plugins  # Mount local 'plugins' directory to Airflow 'plugins' directory
    ports:
      - "8080:8080"  # Expose port 8080 for the webserver
    depends_on:
      - postgres  # Ensure the PostgreSQL service is started before the webserver
    command: webserver  # Command to run the Airflow webserver

  # Airflow scheduler service
  scheduler:
    image: apache/airflow:2.4.3  # Use the official Apache Airflow image version 2.4.3
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor  # Use LocalExecutor for Airflow
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow  # Database connection string
      #AIRFLOW__CORE__FERNET_KEY: 'OExH4KfzQbFU9f2DltIorH3jDP6bHCjSIOXcjssHImM='  # Optional: Fernet key for encryption
      AIRFLOW__CORE__LOAD_EXAMPLES: 'true'  # Load example DAGs
    volumes:
      - ./dags:/opt/airflow/dags  # Mount local 'dags' directory to Airflow 'dags' directory
      - ./logs:/opt/airflow/logs  # Mount local 'logs' directory to Airflow 'logs' directory
      - ./plugins:/opt/airflow/plugins  # Mount local 'plugins' directory to Airflow 'plugins' directory
    depends_on:
      - postgres  # Ensure the PostgreSQL service is started before the scheduler
    command: scheduler  # Command to run the Airflow scheduler

  # Airflow initialization service
  airflow-init:
    image: apache/airflow:2.4.3  # Use the official Apache Airflow image version 2.4.3
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor  # Use LocalExecutor for Airflow
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow  # Database connection string
      #AIRFLOW__CORE__FERNET_KEY: 'OExH4KfzQbFU9f2DltIorH3jDP6bHCjSIOXcjssHImM='  # Optional: Fernet key for encryption
      AIRFLOW__CORE__LOAD_EXAMPLES: 'true'  # Load example DAGs
    volumes:
      - ./dags:/opt/airflow/dags  # Mount local 'dags' directory to Airflow 'dags' directory
      - ./logs:/opt/airflow/logs  # Mount local 'logs' directory to Airflow 'logs' directory
      - ./plugins:/opt/airflow/plugins  # Mount local 'plugins' directory to Airflow 'plugins' directory
    depends_on:
      - postgres  # Ensure the PostgreSQL service is started before the initialization
    entrypoint: >
      /bin/bash -c "sleep 10 && airflow db init && airflow users create --username admin1 --firstname admin --lastname user --role Admin --email admin@gmail.com --password admin123"  # Initialize the Airflow database and create a new user

  minio:
    image: minio/minio:latest
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"  # API (matches your config.json)
      - "9001:9001"  # Web console
    volumes:
      - minio-data:/data
      - ./minio-config/config.json:/opt/config.json  # Corrected config path
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
  # Superset visualization service
  superset:
    image: apache/superset:latest
    environment:
      SUPERSET_SECRET_KEY: 'my_secret_key'
    ports:
      - "8088:8088"
    volumes:
      - ./superset:/app/superset_config
    depends_on:
      - postgres
    command: >
      bash -c "superset db upgrade && 
      superset fab create-admin --username admin --firstname Superset --lastname Admin --email admin@superset.com --password admin && 
      superset init && 
      superset run -p 8088 --with-threads --reload --debugger"

  # pgAdmin service
  pgadmin:
    image: dpage/pgadmin4:latest
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@pgadmin.com
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "5050:80"
    volumes:
      - pgadmin-data:/var/lib/pgadmin
    depends_on:
      - postgres
  
  # jupyter service
  jupyter:
    image: jupyter/base-notebook
    ports:
      - "8888:8888"
    volumes:
      - ./notebooks:/home/jovyan/work
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_TOKEN=ipynbtoken
    depends_on:
      - postgres

volumes:
  postgres-db-volume:  # Define a named volume for PostgreSQL data
  minio-data:  # Define a named volume for MinIO data
  pgadmin-data:  # Define a named volume for pgAdmin data